### 修改
- Embedding2
```python
# autograd/nn.py
class Embedding2(Module):
    def __init__(self, num_embeddings, embedding_dim):
        self.weight = Tensor.parameter(num_embeddings, embedding_dim)
        self._one_hot_metrix = np.eye(num_embeddings, dtype=np.float32)

    def forward(self, indices):
        return self._one_hot_metrix[indices] @ self.weight
```
修改了one_hot方法。使用单位矩阵进行one_hot，更符合标准写法。
- SGD
```python
# autograd/optim.py
class SGD:
    def __init__(self, params, lr=0.01, momentum=0.0):  # 新增 momentum 参数
        self.params = list(params)  # 确保参数列表是可迭代的
        self.lr = lr
        self.momentum = momentum

        # 初始化速度变量，字典存储
        self.velocities = {}
        if self.momentum > 0:
            for p in self.params:
                if p.requires_grad:
                    # 只为需要梯度的参数创建速度
                    self.velocities[p] = np.zeros_like(p.data)

    def step(self):
        for p in self.params:
            # 确保参数需要梯度，并且当前梯度存在
            if p.requires_grad:
                if self.momentum == 0:  # 标准SGD更新
                    p.data -= self.lr * p.grad
                else:
                    current_velocity = self.velocities[p]
                    #  v = momentum * v + lr * grad
                    new_velocity = self.momentum * current_velocity + self.lr * p.grad
                    p.data -= new_velocity
                    self.velocities[p] = new_velocity  # 保存当前速度

    def zero_grad(self):
        for p in self.params:
            if p.grad is not None:
                p.zero_grad()
```
实现了带动量的SGD。为了避免训练过程中在局部极小值点震荡，引入了动量概念。引入动量的SGD将不再单纯通过当前梯度来进行梯度下降，而是根据上一次梯度下降的方向（即历史速度）和当前梯度来计算出梯度下降的方向。这种方法直观上是给梯度下降过程赋予了一定的惯性，有助于克服局部极小值。  
在实际的迭代过程中速度是以动量的指数进行衰减的，这也符合直觉：越近的速度对当前梯度下降的方向影响越大。这同样适用与RMSprob和Adam的更新策略。  
此外，当梯度下降方向长期处于同一方向时，动量的积累会变得非常大。
### 新增
- topk
```python
# autograd/tensor.py
class Tensor:
    ...
    def topk(self, k, axis=-1, largest=True):
    """使用np.argsort配合Tensor.take_along_axis方法实现topk的效果"""
    # 排序
    indices = np.argsort(self.data, axis=axis)
    if largest:
        indices = np.take(indices, range(-1,-k-1,-1), axis=axis)
    else:
        indices = np.take(indices, range(k), axis=axis)

    value = self.take_along_axis(indices, axis=axis)
    return value, indices
```
实现了topk方法用于SparseMOE。主要逻辑是先用argsort将最大值（最小值）的索引找到，然后再根据最大/最小值来将对应k个索引取出。这里需要注意的是取最大值时需要从最大开始依次往前取，因此需要设定range(-1,-k-1,-1)。取到索引后再根据索引将值取出即可。这里复用了已经实现的Tensor.take_along_axis，因此无需考虑梯度问题。
- SparseMOE with aux_loss
```python
# transformer/modern_blocks.py
class SparseMOE(nn.Module):
    def __init__(self, feature_in, feature_out, num_experts, topk):
        self.w = Tensor.parameter(num_experts, feature_in, feature_out)
        self.b = Tensor.parameter(num_experts, feature_out)
        self.gate = Gate(feature_in, num_experts)
        self.topk = topk
        self.num_experts = num_experts
        self.is_train = True

    def forward(self, x):
        # x: b, s, i (feature_in)

        # 传入gate得到概率
        probs = self.gate(x)  # b, s, n (num_experts)

        topk_probs, topk_indices = probs.topk(self.topk)
        topk_probs /= topk_probs.sum(-1, keepdims=True) + 1e-9  # 概率归一化
        w_uns = self.w[topk_indices]  # 选中对应的专家，由于numpy的高级索引机制，形状会变成 b,s,k,i,o
        b_uns = self.b[topk_indices]  # b,s,k,o

        x_uns = x.unsqueeze(2).unsqueeze(-1)  # b,s,1,i,1
        experts_out_uns = x_uns * w_uns  # b,s,k,i,o
        experts_out = experts_out_uns.sum(-2)  # b,s,k,o
        experts_out = experts_out + b_uns  # 加偏置
        experts_out = experts_out.relu()

        probs_uns = topk_probs.unsqueeze(-1)
        out_uns = experts_out * probs_uns

        if not self.is_train:
            return out_uns.sum(-2)

        aux_loss = self._aux_loss(probs, topk_indices)  # 辅助损失
        return out_uns.sum(-2), aux_loss

    def _aux_loss(self, probs, indices, alpha=0.01):
        """计算辅助损失以实现负载均衡"""
        # L = alpha * N * sum(f_i * p_i)
        b, s, n = probs.shape
        assert n == self.num_experts
        P = probs.mean(0).mean(0)  # (n,) 对应每一个expert被选中的平均概率。此处调用两次mean是因为Tensor的mean方法暂时还不支持元组索引

        # 转换为one_hot编码，shape: b,s,k,n
        one_hot_indices = np.eye(n, dtype=np.float32)[indices]
        # 沿k维度求和，可以得到每一个token选中的专家， shape: b,s,n
        expert_chosen_mask = one_hot_indices.sum(axis=2)
        # 计算被选中的比例 (对 b 和 s 维度求平均)
        f = expert_chosen_mask.mean((0,1))  # (n,)。 f一系列的计算都是基于ndarray的，因为对indices的操作不涉及梯度回传
        return alpha * n * (P * f).sum()
```
实现了SparseMOE和MOE辅助损失，我们分开解析。
* SparseMOE  
本质上与DenseMOE没有太大区别，唯一的区别就是只激活k个专家。topk的实现是难点。实现了topk后，我们只需要对gate传出的概率值进行topk筛选并激活对应的expert即可。需要注意的是gate传出的logits经过topk后得到的索引形状为(b,s,k)，通过这个形状的indices对参数(n,i,o)进行取值会自动广播为(b,s,k,i,o)，因此不需要手动unsqueeze。其余的实现和DenseMOE完全类似。
* aux_loss  
我们首先说明为什么需要辅助损失：简单地讲，负载均衡问题。使用MOE时，我们希望每个expert都得到充分的训练。如果gate始终激活某几个expert，这几个expert经过充分训练后同时会让gate也更倾向于一直激活这几个expert，因此会让其余expert得不到训练。为了解决这个问题，引入了辅助损失。由于辅助损失仅由gate输出的expert选择概率以及被选中expert的indices进行计算，因此我选择直接在内部进行计算并传出，增强代码的封装性。  
这里实现的损失函数$L = α * N * \sum {f_i}*{p_i}$，要使损失尽量小，本质上是将每个token选中专家的概率平均化，即减少$\sum {f_i}*{p_i}$的方差，因此可以让gate输出概率尽量平均，让每个expert充分得到训练。需要注意的是probs始终进行张量运算，因为需要进行梯度回传更新gate层参数；t由于是对索引的各种操作，不涉及梯度回传，因此使用np进行计算。  
这里同时加入了is_train参数用于控制是否计算辅助损失。
- RMSprob
```python
# autograd/optim.py
class RMSprop:
    def __init__(self, params, lr=0.01, beta=0.99, eps=1e-9):
        """
        初始化RMSprop优化器
        :param params:
        :param lr:
        :param beta: 梯度平方的指数移动平均衰减率，即过去梯度对当前的影响程度。β越大过去的影响越大，当前梯度的影响越小
        :param eps: 防止除0的极小值
        """
        self.params = list(params)
        self.lr = lr
        self.beta = beta
        self.eps = eps

        # 与SGD的实现一样，字典存储
        self.v = {}
        for p in self.params:
            if p.requires_grad:
                self.v[p] = np.zeros_like(p.data)

    def step(self):
        for p in self.params:
            if p.requires_grad:
                g = p.grad
                current_v = self.v[p]
                # v_t = beta * v_{t-1} + (1 - beta) * g_t^2
                new_v = self.beta * current_v + (1 - self.beta) * g ** 2

                # theta_t = theta_{t-1} - lr * g_t / (sqrt(v_t) + eps)
                p.data = p.data - self.lr * g / (np.sqrt(new_v) + self.eps)
                self.v[p] = new_v  # 更新字典

    def zero_grad(self):
        for p in self.params:
            if p.grad is not None:
                p.zero_grad()
```
实现了RMSprob优化器。RMSprob解决了梯度下降过程中不同参数更新策略的问题：如果某个参数梯度较大，其梯度下降的较快，可能会越过极小值点（与较大学习率引发的效果相同），RMSprob根据梯度的均方差（直观反映了梯度的“大小”）来对学习率进行缩放，梯度的均方差越大，实际的学习率越小，解决了参数在梯度较大时可能引发的震荡问题。  
此外，均方差越小，学习率越大，RMSprob还起到了一定的加速作用。
与momentum的实现类似，也是存储每一个参数的均方根状态然后根据均方根对学习率进行缩放。由于RMSprob对不同参数会使用不同的学习率，因此对基础学习率不敏感。
- Adam
```python
# autograd/optim.py
class Adam:
    def __init__(self, params, lr=0.01, beta1=0.9, beta2=0.999, eps=1e-9):
        self.params = list(params)
        self.lr = lr
        self.beta1 = beta1
        self.beta2 = beta2
        self.eps = eps
        self.t = 0  # 时间步，用于消除训练初期偏差问题

        self.m, self.v = {}, {}
        for p in self.params:
            if p.requires_grad:
                self.m[p] = np.zeros_like(p.data)
                self.v[p] = np.zeros_like(p.data)

    def step(self):
        self.t += 1
        for p in self.params:
            if p.requires_grad:
                g = p.grad
                current_m, current_v = self.m[p], self.v[p]
                new_m = self.beta1 * current_m + (1 - self.beta1) * g
                new_v = self.beta2 * current_v + (1 - self.beta2) * g ** 2

                # 使用时间步进行偏差修正
                m_modified = new_m / (1 - self.beta1 ** self.t)
                v_modified = new_v / (1 - self.beta2 ** self.t)

                # 梯度下降
                p.data -= self.lr * m_modified / (np.sqrt(v_modified) + self.eps)

                # 更新字典
                self.m[p] = new_m
                self.v[p] = new_v

    def zero_grad(self):
        for p in self.params:
            if p.grad is not None:
                p.zero_grad()
```
吸取了SGD with momentum的惯性以及RMSprob对参数自适应学习率。本质上和momentum以及RMSprob的计算完全类似:通过一阶矩决定梯度下降的方向，同时通过二阶矩(均方根就是二阶矩的平均值)决定梯度下降的速度。这里引入了时间步的概念，因为训练初期由于beta值设定都非常接近1，导致未经偏差修正的一阶矩和二阶矩都非常小，训练初期缓慢。引入时间步可以在训练初期对一二阶矩进行缩放并在训练后期减少影响。